{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7840403b-f338-4520-8b2c-011fc4a5e8d4",
   "metadata": {},
   "source": [
    "## GROCERY CLASSIFER\n",
    "A trained CNN that, through image recognition, will output the highest probable type of fruit or vegetable. A dataset of 90480 images (that can be found in this <a href=\"https://www.kaggle.com/datasets/moltean/fruits\">link</a>) are being used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8efb381-54f2-42d1-a452-2c088895fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2a2c7-d6e5-4a7b-9dde-2bc57732986a",
   "metadata": {},
   "source": [
    "#### HANDLING DATASET\n",
    "In this section we'll be handling the dataset and checking its format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64abb4b0-e485-4235-94c8-90b99c5e7daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"fruits-360/\"\n",
    "train_dir = data_dir+\"train/\"\n",
    "test_dir = data_dir+\"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b265bdf3-f250-4e43-a8e2-f89609d60f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a transform object for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(100),\n",
    "    transforms.CenterCrop(30),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# creating a dataset from folder\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "\n",
    "# creating train loader from dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# creating a transform object for testing\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(100),\n",
    "    transforms.RandomCrop(30),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# creating a dataset from folder\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "# creating train loader from dataset\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50625b0f-6c2e-482b-990e-2d8621ebe35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
